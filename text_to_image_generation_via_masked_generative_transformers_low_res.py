# -*- coding: utf-8 -*-
"""Text-To-Image Generation via Masked Generative Transformers-Low Res.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IyRS0FAvLMPSvU0PQf5x_iKNMW1YWMp_

## Text-To-Image Generation via Masked Generative Transformers
1.   **Algorithm** (Muse-Low Res)
2.   **Library** (torch, muse_maskgit_pytorch)
3.   **Result** (High-Quality Text-to-Image Conversion Using Masked Generative Transformers)

> **Installing the Required Libraries**
"""

pip install muse-maskgit-pytorch

"""

> **Train VAE**
1. Number of Images = 20
2. Number of Train Steps = 500

"""

import torch
from muse_maskgit_pytorch import VQGanVAE, VQGanVAETrainer

vae = VQGanVAE(
    dim = 256,
    codebook_size = 65536
)

trainer = VQGanVAETrainer(
    vae = vae,
    image_size = 128,
    folder = '/content/drive/MyDrive/Text To Image Generation/Muse-Masked Generative Transformers/images',
    batch_size = 4,
    grad_accum_every = 8,
    num_train_steps = 500
).cuda()

trainer.train()

"""

> **Save VAE**

"""

torch.save(vae.state_dict(), '/content/drive/MyDrive/Text To Image Generation/Muse-Masked Generative Transformers/vae_model.pt')

"""

> **Pass the Trained VQGanVAE and a Transformer to MaskGit**

"""

import torch
from muse_maskgit_pytorch import VQGanVAE, MaskGit, MaskGitTransformer

# first instantiate your vae

vae = VQGanVAE(
    dim = 256,
    codebook_size = 65536
).cuda()

vae.load('/content/drive/MyDrive/Text To Image Generation/Muse-Masked Generative Transformers/vae_model.pt')

# then you plug the vae and transformer into your MaskGit as so

# (1) create your transformer / attention network

transformer = MaskGitTransformer(
    num_tokens = 65536,       # must be same as codebook size above
    seq_len = 256,            # must be equivalent to fmap_size ** 2 in vae
    dim = 512,                # model dimension
    depth = 8,                # depth
    dim_head = 64,            # attention head dimension
    heads = 8,                # attention heads,
    ff_mult = 4,              # feedforward expansion factor
    t5_name = 't5-small',     # name of your T5
)

# (2) pass your trained VAE and the base transformer to MaskGit

base_maskgit = MaskGit(
    vae = vae,                 # vqgan vae
    transformer = transformer, # transformer
    image_size = 256,          # image size
    cond_drop_prob = 0.25,     # conditional dropout, for classifier free guidance
).cuda()

# ready your training text and images
import pandas as pd
from PIL import Image
import torch
import torchvision.transforms as transforms
import os

transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

excel_file = '/content/drive/MyDrive/Text To Image Generation/Muse-Masked Generative Transformers/Image Number-Text-Second.xlsx'
data = pd.read_excel(excel_file)

images = []
texts = data['text'].tolist()

for image_file in data['image_filename']:
    image = Image.open(f'/content/drive/MyDrive/Text To Image Generation/Muse-Masked Generative Transformers/images - Second/{image_file}').convert("RGB")
    image = transform(image)
    images.append(image)

images = torch.stack(images).cuda()


# feed it into your maskgit instance, with return_loss set to True

loss = base_maskgit(
    images,
    texts = texts
)

loss.backward()

# do this for a long time on much data
# then...

"""

> **Generating New Images with Muse**
"""

images = base_maskgit.generate(texts = [
    'A red bus',
    'A parked motorcycle',
    'Children standing near a boat'
], cond_scale = 3.) # conditioning scale for classifier free guidance

images.shape # (3, 3, 256, 256)

import matplotlib.pyplot as plt
import numpy as np

images = images.cpu().numpy() if images.is_cuda else images.numpy()

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for i in range(3):
    img = np.clip(images[i].transpose(1, 2, 0), 0, 1)

    axes[i].imshow(img)
    axes[i].axis('off')

plt.show()