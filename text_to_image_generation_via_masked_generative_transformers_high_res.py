# -*- coding: utf-8 -*-
"""Text-To-Image Generation via Masked Generative Transformers-High Res.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hSdKkug1ZYR5W0dIwbUE4gnBvIZMYXiK

## Text-To-Image Generation via Masked Generative Transformers
1.   **Algorithm** (Muse-Super Resolution)
2.   **Library** (torch, muse_maskgit_pytorch)
3.   **Result** (High-Quality Text-to-Image Conversion Using Masked Generative Transformers)

> **Installing the Required Libraries**
"""

pip install muse-maskgit-pytorch

"""> **Train VAE**
          
          For training the VAE in super-resolution mode, the pre-trained file from the low-resolution mode is used.

> **Pass the Trained VQGanVAE and a Transformer to MaskGit**
"""

import torch
from muse_maskgit_pytorch import VQGanVAE, MaskGit, MaskGitTransformer
import torch.nn.functional as F

# first instantiate your vae

vae = VQGanVAE(
    dim = 256,
    codebook_size = 65536
).cuda()

vae.load('/content/drive/MyDrive/Text To Image Generation/Muse-Masked Generative Transformers/vae_model.pt')

# then you plug the vae and transformer into your MaskGit as so

# (1) create your transformer / attention network

transformer = MaskGitTransformer(
    num_tokens = 65536,       # must be same as codebook size above
    seq_len = 1024,            # must be equivalent to fmap_size ** 2 in vae
    dim = 512,                # model dimension
    depth = 2,                # depth
    dim_head = 64,            # attention head dimension
    heads = 8,                # attention heads,
    ff_mult = 4,              # feedforward expansion factor
    t5_name = 't5-small',     # name of your T5
)

# (2) pass your trained VAE and the base transformer to MaskGit

superres_maskgit = MaskGit(
    vae = vae,
    transformer = transformer,
    cond_drop_prob = 0.25,
    image_size = 512,                     # larger image size
    cond_image_size = 256,                # conditioning image size <- this must be set
).cuda()

# ready your training text and images
import pandas as pd
from PIL import Image
import torch
import torchvision.transforms as transforms
import os

transform = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor()
])

excel_file = '/content/drive/MyDrive/Text To Image Generation/Muse-Masked Generative Transformers/Image Number-Text-High Res.xlsx'
data = pd.read_excel(excel_file)

images = []
texts = data['text'].tolist()

for image_file in data['image_filename']:
    image = Image.open(f'/content/drive/MyDrive/Text To Image Generation/Muse-Masked Generative Transformers/Images-High Res/{image_file}').convert("RGB")
    image = transform(image)
    images.append(image)

images = torch.stack(images).cuda()


# feed it into your maskgit instance, with return_loss set to True

loss = superres_maskgit(
    images,
    texts = texts
)

loss.backward()

# do this for a long time on much data
# then...

"""

> **Generating New Images with Muse**
"""

generated_images = superres_maskgit.generate(
    texts=[
        'A red bus with a clock',
        'A parked motorcycle with a clock',
        'Children standing near a boat',
        'A beautiful landscape'
    ],
    cond_images=images,  # Use the original 512x512 images as conditioning images
    cond_scale=3.0
)

import matplotlib.pyplot as plt

# Move generated images to CPU and normalize to [0, 1] range if necessary
generated_images = generated_images.cpu().detach().clamp(0, 1)  # Ensure values are within [0, 1]

# Plot each image
for i, img in enumerate(generated_images):
    plt.figure()
    plt.imshow(img.permute(1, 2, 0).numpy())  # Convert from (C, H, W) to (H, W, C)
    plt.title(f"Generated Image {i + 1}")
    plt.axis('off')
    plt.show()